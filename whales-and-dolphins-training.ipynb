{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importing Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-03-19T11:02:27.114225Z",
     "iopub.execute_input": "2022-03-19T11:02:27.114469Z",
     "iopub.status.idle": "2022-03-19T11:02:28.279161Z",
     "shell.execute_reply.started": "2022-03-19T11:02:27.114422Z",
     "shell.execute_reply": "2022-03-19T11:02:28.278480Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "root_dir = \"data/\"\n",
    "train_dir = os.path.join(root_dir, \"train_images\")\n",
    "train_csv = os.path.join(root_dir, \"train_data.csv\")\n",
    "test_dir = os.path.join(root_dir, \"test_images\")\n",
    "test_csv = os.path.join(root_dir, \"test_data.csv\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-19T11:02:28.281278Z",
     "iopub.execute_input": "2022-03-19T11:02:28.281586Z",
     "iopub.status.idle": "2022-03-19T11:02:28.285469Z",
     "shell.execute_reply.started": "2022-03-19T11:02:28.281561Z",
     "shell.execute_reply": "2022-03-19T11:02:28.284957Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_csv)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-19T11:02:28.286960Z",
     "iopub.execute_input": "2022-03-19T11:02:28.287246Z",
     "iopub.status.idle": "2022-03-19T11:02:28.609296Z",
     "shell.execute_reply.started": "2022-03-19T11:02:28.287219Z",
     "shell.execute_reply": "2022-03-19T11:02:28.608702Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Train Dataset:{len(train_df)} and Test Dataset {len(test_df)}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-19T11:02:28.610182Z",
     "iopub.execute_input": "2022-03-19T11:02:28.610364Z",
     "iopub.status.idle": "2022-03-19T11:02:28.614226Z",
     "shell.execute_reply.started": "2022-03-19T11:02:28.610341Z",
     "shell.execute_reply": "2022-03-19T11:02:28.613548Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:51033 and Test Dataset 27956\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-19T11:02:28.615054Z",
     "iopub.execute_input": "2022-03-19T11:02:28.615212Z",
     "iopub.status.idle": "2022-03-19T11:02:28.740274Z",
     "shell.execute_reply.started": "2022-03-19T11:02:28.615191Z",
     "shell.execute_reply": "2022-03-19T11:02:28.739559Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                image             species individual_id  \\\n0  00021adfb725ed.jpg  melon_headed_whale  cadddb1636b9   \n1  000562241d384d.jpg      humpback_whale  1a71fbb72250   \n2  0007c33415ce37.jpg  false_killer_whale  60008f293a2b   \n3  0007d9bca26a99.jpg  bottlenose_dolphin  4b00fe572063   \n4  00087baf5cef7a.jpg      humpback_whale  8e5253662392   \n\n                                   path    class  width  height  split  \n0  data/train_images/00021adfb725ed.jpg    whale    804     671  Train  \n1  data/train_images/000562241d384d.jpg    whale   3504    2336  Train  \n2  data/train_images/0007c33415ce37.jpg    whale   3599    2399  Train  \n3  data/train_images/0007d9bca26a99.jpg  dolphin   3504    2336  Train  \n4  data/train_images/00087baf5cef7a.jpg    whale   3599    2699  Train  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>species</th>\n      <th>individual_id</th>\n      <th>path</th>\n      <th>class</th>\n      <th>width</th>\n      <th>height</th>\n      <th>split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00021adfb725ed.jpg</td>\n      <td>melon_headed_whale</td>\n      <td>cadddb1636b9</td>\n      <td>data/train_images/00021adfb725ed.jpg</td>\n      <td>whale</td>\n      <td>804</td>\n      <td>671</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000562241d384d.jpg</td>\n      <td>humpback_whale</td>\n      <td>1a71fbb72250</td>\n      <td>data/train_images/000562241d384d.jpg</td>\n      <td>whale</td>\n      <td>3504</td>\n      <td>2336</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0007c33415ce37.jpg</td>\n      <td>false_killer_whale</td>\n      <td>60008f293a2b</td>\n      <td>data/train_images/0007c33415ce37.jpg</td>\n      <td>whale</td>\n      <td>3599</td>\n      <td>2399</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0007d9bca26a99.jpg</td>\n      <td>bottlenose_dolphin</td>\n      <td>4b00fe572063</td>\n      <td>data/train_images/0007d9bca26a99.jpg</td>\n      <td>dolphin</td>\n      <td>3504</td>\n      <td>2336</td>\n      <td>Train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00087baf5cef7a.jpg</td>\n      <td>humpback_whale</td>\n      <td>8e5253662392</td>\n      <td>data/train_images/00087baf5cef7a.jpg</td>\n      <td>whale</td>\n      <td>3599</td>\n      <td>2699</td>\n      <td>Train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Label Mapping"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "species = list(train_df.species.unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "['melon_headed_whale',\n 'humpback_whale',\n 'false_killer_whale',\n 'bottlenose_dolphin',\n 'beluga_whale',\n 'minke_whale',\n 'fin_whale',\n 'blue_whale',\n 'gray_whale',\n 'southern_right_whale',\n 'common_dolphin',\n 'killer_whale',\n 'short_finned_pilot_whale',\n 'dusky_dolphin',\n 'long_finned_pilot_whale',\n 'sei_whale',\n 'spinner_dolphin',\n 'cuviers_beaked_whale',\n 'spotted_dolphin',\n 'brydes_whale',\n 'commersons_dolphin',\n 'white_sided_dolphin',\n 'rough_toothed_dolphin',\n 'pantropic_spotted_dolphin',\n 'pygmy_killer_whale',\n 'frasiers_dolphin']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "label_map = {}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "for i in range(0, len(species)):\n",
    "    label_map[species[i]] = i"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "{'melon_headed_whale': 0,\n 'humpback_whale': 1,\n 'false_killer_whale': 2,\n 'bottlenose_dolphin': 3,\n 'beluga_whale': 4,\n 'minke_whale': 5,\n 'fin_whale': 6,\n 'blue_whale': 7,\n 'gray_whale': 8,\n 'southern_right_whale': 9,\n 'common_dolphin': 10,\n 'killer_whale': 11,\n 'short_finned_pilot_whale': 12,\n 'dusky_dolphin': 13,\n 'long_finned_pilot_whale': 14,\n 'sei_whale': 15,\n 'spinner_dolphin': 16,\n 'cuviers_beaked_whale': 17,\n 'spotted_dolphin': 18,\n 'brydes_whale': 19,\n 'commersons_dolphin': 20,\n 'white_sided_dolphin': 21,\n 'rough_toothed_dolphin': 22,\n 'pantropic_spotted_dolphin': 23,\n 'pygmy_killer_whale': 24,\n 'frasiers_dolphin': 25}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "train_df['label'] = train_df['species'].apply(lambda x: label_map.get(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                image             species individual_id  \\\n0  00021adfb725ed.jpg  melon_headed_whale  cadddb1636b9   \n1  000562241d384d.jpg      humpback_whale  1a71fbb72250   \n2  0007c33415ce37.jpg  false_killer_whale  60008f293a2b   \n3  0007d9bca26a99.jpg  bottlenose_dolphin  4b00fe572063   \n4  00087baf5cef7a.jpg      humpback_whale  8e5253662392   \n\n                                   path    class  width  height  split  label  \n0  data/train_images/00021adfb725ed.jpg    whale    804     671  Train      0  \n1  data/train_images/000562241d384d.jpg    whale   3504    2336  Train      1  \n2  data/train_images/0007c33415ce37.jpg    whale   3599    2399  Train      2  \n3  data/train_images/0007d9bca26a99.jpg  dolphin   3504    2336  Train      3  \n4  data/train_images/00087baf5cef7a.jpg    whale   3599    2699  Train      1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>species</th>\n      <th>individual_id</th>\n      <th>path</th>\n      <th>class</th>\n      <th>width</th>\n      <th>height</th>\n      <th>split</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00021adfb725ed.jpg</td>\n      <td>melon_headed_whale</td>\n      <td>cadddb1636b9</td>\n      <td>data/train_images/00021adfb725ed.jpg</td>\n      <td>whale</td>\n      <td>804</td>\n      <td>671</td>\n      <td>Train</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000562241d384d.jpg</td>\n      <td>humpback_whale</td>\n      <td>1a71fbb72250</td>\n      <td>data/train_images/000562241d384d.jpg</td>\n      <td>whale</td>\n      <td>3504</td>\n      <td>2336</td>\n      <td>Train</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0007c33415ce37.jpg</td>\n      <td>false_killer_whale</td>\n      <td>60008f293a2b</td>\n      <td>data/train_images/0007c33415ce37.jpg</td>\n      <td>whale</td>\n      <td>3599</td>\n      <td>2399</td>\n      <td>Train</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0007d9bca26a99.jpg</td>\n      <td>bottlenose_dolphin</td>\n      <td>4b00fe572063</td>\n      <td>data/train_images/0007d9bca26a99.jpg</td>\n      <td>dolphin</td>\n      <td>3504</td>\n      <td>2336</td>\n      <td>Train</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00087baf5cef7a.jpg</td>\n      <td>humpback_whale</td>\n      <td>8e5253662392</td>\n      <td>data/train_images/00087baf5cef7a.jpg</td>\n      <td>whale</td>\n      <td>3599</td>\n      <td>2699</td>\n      <td>Train</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    transforms.Resize((32,32)),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "number_of_labels = 26"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# def load_split_train_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class WhaleDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, image_dir: str, transform: None):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.image_paths = self.df.path\n",
    "        self.labels = self.df.label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image_path = self.image_paths.iloc[item]\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = self.transform(image)\n",
    "        label = self.labels.iloc[item]\n",
    "\n",
    "        return image, label\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "valid_data_split = 0.1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "valid_df = train_df.sample(frac=valid_data_split, replace=False, random_state=1).copy()\n",
    "train_df = train_df[~train_df['image'].isin(valid_df['image'])].copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45930, 9)\n",
      "(5103, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(valid_df.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "train_df.reset_index(drop=True, inplace=True)\n",
    "valid_df.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "training_dataset = WhaleDataset(df=train_df, image_dir=train_dir, transform=transformations)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "validation_dataset = WhaleDataset(df=valid_df, image_dir=train_dir, transform=transformations)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "45930"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "5103"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "dataset_dict = {\"train\": training_dataset, \"val\": validation_dataset}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "valid_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "4593"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "511"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model steup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class CnnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CnnModel, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(12)\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(12)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv4 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(24)\n",
    "        self.conv5 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(24)\n",
    "        self.fc1 = nn.Linear(24*10*10, 26)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = nn.functional.relu(self.bn1(self.conv1(input)))\n",
    "        output = nn.functional.relu(self.bn2(self.conv2(output)))\n",
    "        output = self.pool(output)\n",
    "        output = nn.functional.relu(self.bn4(self.conv4(output)))\n",
    "        output = nn.functional.relu(self.bn5(self.conv5(output)))\n",
    "        output = output.view(-1, 24*10*10)\n",
    "        output = self.fc1(output)\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-19T11:03:02.806961Z",
     "iopub.execute_input": "2022-03-19T11:03:02.807633Z",
     "iopub.status.idle": "2022-03-19T11:21:29.757135Z",
     "shell.execute_reply.started": "2022-03-19T11:03:02.807602Z",
     "shell.execute_reply": "2022-03-19T11:21:29.756681Z"
    },
    "trusted": true
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = CnnModel()"
   ],
   "metadata": {},
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Function to save the model\n",
    "def save_model():\n",
    "    path = \"./CnnModel.pth\"\n",
    "    torch.save(model.state_dict(), path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Function to test the model with the validation dataset and print the accuracy for the test images\n",
    "def vaild_accuracy():\n",
    "\n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            images, labels = data\n",
    "            # run the model on the test set to predict labels\n",
    "            images = Variable(images.to(device))\n",
    "            labels = Variable(labels.to(device))\n",
    "            outputs = model(images)\n",
    "\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.\n",
    "def train(num_epochs):\n",
    "\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    # Define your execution device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"The model will be running on\", device, \"device\")\n",
    "    # Convert model parameters and buffers to CPU or Cuda\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader, 0):\n",
    "\n",
    "            # get the inputs\n",
    "            images = Variable(images.to(device))\n",
    "            labels = Variable(labels.to(device))\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # predict classes using images from the training set\n",
    "            outputs = model(images)\n",
    "            # compute the loss based on model output and real labels\n",
    "            loss = loss_function(outputs, labels)\n",
    "            # backpropagation the loss\n",
    "            loss.backward()\n",
    "            # adjust parameters based on the calculated gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # Let's print statistics for every 1,000 images\n",
    "            running_loss += loss.item()     # extract the loss value\n",
    "            if i % 1000 == 999:\n",
    "                # print every 1000 (twice per epoch)\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 1000))\n",
    "                # zero the loss\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Compute and print the average accuracy fo this epoch when tested over all 10000 test images\n",
    "        accuracy = vaild_accuracy()\n",
    "        print('For epoch', epoch + 1,'the test accuracy over the whole test set is %d %%' % accuracy)\n",
    "\n",
    "        # we want to save the model if the accuracy is the best\n",
    "        if accuracy > best_accuracy:\n",
    "            save_model()\n",
    "            best_accuracy = accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be running on cuda:0 device\n",
      "[1,  1000] loss: 1.653\n",
      "[1,  2000] loss: 1.297\n",
      "[1,  3000] loss: 1.193\n",
      "[1,  4000] loss: 1.122\n",
      "For epoch 1 the test accuracy over the whole test set is 66 %\n",
      "[2,  1000] loss: 1.079\n",
      "[2,  2000] loss: 1.001\n",
      "[2,  3000] loss: 0.975\n",
      "[2,  4000] loss: 0.937\n",
      "For epoch 2 the test accuracy over the whole test set is 70 %\n",
      "[3,  1000] loss: 0.906\n",
      "[3,  2000] loss: 0.886\n",
      "[3,  3000] loss: 0.870\n",
      "[3,  4000] loss: 0.847\n",
      "For epoch 3 the test accuracy over the whole test set is 72 %\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs=num_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
